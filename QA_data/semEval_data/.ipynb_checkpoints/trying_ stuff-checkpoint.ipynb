{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import match_sentences\n",
    "import similarity_model\n",
    "from data_reading import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anavgg/Documents/Current projects/QA_data/data/semeval2016-task3-cqa-ql-traindev-v3.2 ENG/v3.2/dev/SemEval2016-Task3-CQA-QL-dev-subtaskA.xml',\n",
       " '/home/anavgg/Documents/Current projects/QA_data/data/semeval2016-task3-cqa-ql-traindev-v3.2 ENG/v3.2/dev/SemEval2016-Task3-CQA-QL-dev.xml']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafolder_test = \"/home/anavgg/Documents/Current projects/QA_data/data/TEST_INPUT/SemEval2016_task3_test_input/English\"\n",
    "\n",
    "filepaths_test = [os.path.join(datafolder_test, f) for f in os.listdir(datafolder_test) if \"xml\" in f and \"multiline\" not in f]\n",
    "filepaths_test\n",
    "#############################\n",
    "\n",
    "datafolder_train = \"/home/anavgg/Documents/Current projects/QA_data/data/semeval2016-task3-cqa-ql-traindev-v3.2 ENG/v3.2/train\"\n",
    "\n",
    "filepaths_train = [os.path.join(datafolder_train, f) for f in os.listdir(datafolder_train) if \"xml\" in f and \"multiline\" not in f]\n",
    "filepaths_train\n",
    "\n",
    "################################\n",
    "datafolder_dev = \"/home/anavgg/Documents/Current projects/QA_data/data/semeval2016-task3-cqa-ql-traindev-v3.2 ENG/v3.2/dev\"\n",
    "\n",
    "filepaths_dev = [os.path.join(datafolder_dev, f) for f in os.listdir(datafolder_dev) if \"xml\" in f and \"multiline\" not in f]\n",
    "filepaths_dev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplefile = '/home/anavgg/Documents/Current projects/QA_data/data/semeval2016-task3-cqa-ql-traindev-v3.2 ENG/v3.2/dev/SemEval2016-Task3-CQA-QL-dev.xml'\n",
    "rel_answers = []\n",
    "#gathering all relevant answers\n",
    "\n",
    "tree = ET.parse(samplefile)\n",
    "root = tree.getroot()\n",
    "for content in root.iter('RelComment'):\n",
    "    if content.find('RelCText') != None:\n",
    "      \n",
    "     \n",
    "        if [content.attrib, content.find('RelCText').text] not in rel_answers :\n",
    "            #print(content.attrib)\n",
    "            rel_answers.append([content.attrib, content.find('RelCText').text])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_orgq(filepaths_list):\n",
    "    new_queries = []\n",
    "\n",
    "    for fil in filepaths_list:\n",
    "        tree = ET.parse(fil)\n",
    "        root = tree.getroot()\n",
    "        for content in root.iter('OrgQuestion'):\n",
    "            if [content.attrib, content.find('OrgQSubject').text , content.find('OrgQBody').text] not in new_queries :\n",
    "            #print(root.find('./OrgQuestion').attrib['ORGQ_ID'])\n",
    "                new_queries.append((content.attrib, content.find('OrgQSubject').text , content.find('OrgQBody').text))\n",
    "\n",
    "    return new_queries\n",
    "\n",
    "#gathering all relevant questions\n",
    "def get_relq(filepaths_list):\n",
    "\n",
    "    rel_questions = []\n",
    "\n",
    "\n",
    "    for fil in filepaths_list:\n",
    "        tree = ET.parse(fil)\n",
    "        root = tree.getroot()\n",
    "        for content in root.iter('RelQuestion'):\n",
    "            if [content.attrib, content.find('RelQSubject').text , content.find('RelQBody').text] not in rel_questions :\n",
    "                #print(content.attrib)\n",
    "                rel_questions.append((content.attrib, content.find('RelQSubject').text , content.find('RelQBody').text))\n",
    "    return rel_questions\n",
    "\n",
    "##figure out later why this one doesnt work\n",
    "##work on question to question similarity matching for now\n",
    "\n",
    "def get_rela(filepaths_list):\n",
    "    rel_answers = []\n",
    "    #gathering all relevant answers\n",
    "    for fil in filepaths:\n",
    "        tree = ET.parse(fil)\n",
    "        root = tree.getroot()\n",
    "        for content in root.iter('RelComment'):\n",
    "            print()\n",
    "            if content.find('RelCText').text:\n",
    "                if [content.attrib, content.find('RelCText').text] not in rel_answers :\n",
    "                    #print(content.attrib)\n",
    "                    rel_answers.append((content.attrib, content.find('RelCText').text))\n",
    "\n",
    "            \n",
    "    return rel_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_orgq = get_orgq(filepaths_train)\n",
    "train_relq = get_relq(filepaths_train)\n",
    "\n",
    "test_orgq = get_orgq(filepaths_test)\n",
    "test_relq = get_relq(filepaths_test)\n",
    "#test_rela = get_rela(filepaths_test)\n",
    "\n",
    "\n",
    "dev_orgq = get_orgq(filepaths_dev)\n",
    "dev_relq = get_relq(filepaths_dev)\n",
    "#dev_rela = get_rela(filepaths_dev)\n",
    "###############################\n",
    "\n",
    "#up to this point notebook is clean, past this point shit is messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_orgq[10][0][\"ORGQ_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q201'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relq[0][0]['RELQ_ID'].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_questions = []\n",
    "for i in train_relq:\n",
    "    #saving data in the following format\n",
    "    # (ORG_id, RELQ_id, relevance, text)\n",
    "    if \"RELQ_RELEVANCE2ORGQ\" in i[0].keys():\n",
    "        rel_questions.append((i[0]['RELQ_ID'].split(\"_\")[0],i[0]['RELQ_ID'], i[0][\"RELQ_RELEVANCE2ORGQ\"], i[2]))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###extract the glove embeddings using the same model as NLI\n",
    "##MNLI uses glove.840B.300d.txt whic can be found in the multinli data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-9f888a9fb85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglovemodelfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_NONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11138)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:12175)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas/_libs/parsers.c:14136)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas/_libs/parsers.c:14858)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype (pandas/_libs/parsers.c:15629)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m     \"\"\"\n\u001b[1;32m    742\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "## need to read in embeddings from glove and in order to build my embedding space\n",
    "## need to wait until i got access to server or new laptop\n",
    "words = pd.read_table(glovemodelfile, sep= \" \", index_col = 0, header=None, quoting = csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-fcd1319f1988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#output text vectors into word2vec format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mglovemodelfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/anavgg/Documents/Current projects/MNLI code/multiNLI/data/glove.840B.300d.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mglove2word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglovemodelfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"glove_word2vec.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/scripts/glove2word2vec.py\u001b[0m in \u001b[0;36mglove2word2vec\u001b[0;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mglove2word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"\"\"Convert `glove_input_file` in GloVe format into `word2vec_output_file` in word2vec format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mnum_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_glove_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"converting %i vectors from %s to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_input_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_output_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/scripts/glove2word2vec.py\u001b[0m in \u001b[0;36mget_glove_info\u001b[0;34m(glove_file_name)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnum_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnum_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/scripts/glove2word2vec.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"\"\"Return the number of vectors and dimensions in a file in GloVe format.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mnum_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_file_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mnum_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#output text vectors into word2vec format\n",
    "glovemodelfile = \"/home/anavgg/Documents/Current projects/MNLI code/multiNLI/data/glove.840B.300d.txt\"\n",
    "glove2word2vec(glove_input_file=glovemodelfile, word2vec_output_file=\"glove_word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing similarities\n",
      "Most similar 5 sentences to source sentence: Am i going to be penalize by mistakenly jumping the red light but reverse back when realized it was not yet green?\n",
      "0.717943659896\tI have been flashed twice at the Toyota Tower Signals for jumping the red light but luckily the cameras are still in the testing phase . Not all those ugly speed cameras are fully operational . They havent all yet been connected to the ministry of interior ' s sever . Once I was behind a truck at a signal and I couldnt see whether it was green or red when I was crossing . These huge trucks block the sight of the signals . They have to do something about it . Anyways I would definitely advise people not to jump redlights and slow down at the singals .\n",
      "0.695282874127\t\" . . . but locals are obliged to wear it . I was told at work that they even get an allowance to wear the costume (not sure from the company or the state) . They are not supposed to wear anything else while in Qatar . It is sort displaying that you belong to a certain race when you ' re in a minority situation; and i ' m not going into the VIP territory again . As for western women wearing it; as long as you ' re not walking \"\"alone\"\"; it should be OK . At the least you should be walking with another woman; preferably wearing the same . If you two get into a Landcruiser at the end of your walk; that ' s even better :) Moudir\"\n",
      "0.692034128549\tIs that I can ' t see a problem with going off topic if the thread is a light one; such as Paul arranging a social get - together or someone putting up a joke for everyone to have a go at or add to etc . I think the problem is if someone has started a serious thread; which requires a discussion or even an answer to a query they have (if it doesn ' t fit in the more serious forums); then by hijacking it kind of kills the thread and serves no purpose . Speaking as someone who found this site when in the UK; before coming over to Doha; I typed into google a question about; say; sports clubs in Doha and found a thread in QL . It was informative; but I wonder what I would have thought of the site had the thread suddenly disintegrated in people gossiping and heresay and bickering? For a start I would never had seen some of the REAL info I was looking for and given up; as probably would have the person who posted the question in the first place expecting some knowledge to be imparted ! OK - am going to . . . . .\n",
      "0.687745393331\tSounds like you were reasonably lucky; being rear - ended is one of my worst fears when driving having been hit so hard years ago in the UK that my shoulder required surgery (now full of screws . . ); that was from the seat - belt . . . . ! Still wear one; whether in the front or back; but at lights etc I ' ve always got a weather eye on that rear - view mirror; just in case . . . . . Novita; hell I called into my office in Dubai this morning . . . ! True ! I think I smelt like a brewery though lol . . . Though fully admit I ' m not looking forward to hearing that bloody alarm clock going off . . . britexpat; thanks; it ' s good to be back !\n",
      "0.667124054394\t\"Well; for one thing; you don ' t just move to Qatar . You have to have a residence visa; which means you have to be sponsored; usually by a family member or an employer . They ' re not going to let your BF sponsor you . Can you live together? If you don ' t mind living illegally; sure; you can live together . Whether this in fact turns into a problem will depend on a whole lot of factors; but you should be aware that it CAN turn into the sort of problem that spells p - r - i - s - o - n and d - e - p - o - r - t - a - t - i - o - n . You can drink; lots of people do (I do); but you will be in a Muslim country under Sharia law . You would be well advised to be very discreet . Lastly; Qatar would not be my first choice if having \"\"a good time\"\" were all that important to me . I think of it more as a place that one navigates as best one can . It ' s not all that bad a place to live; but you do have to be somewhat resourceful . \"\n",
      "0.660098546094\tMy son was playing with some neighborhood kids and they had said to him that Israeli planes were going to drop bombs on everyone and that they kill people when they find them . . . got him really wound up and scared . So I explained to him that the other kids were Muslim; and they they believed certain things that we didn ' t necessarily believe in . They don ' t they don ' t eat pork; we do; we believe in Santa; they don ' t; etc . I then went on to explain about how some countries fight and go to war with one another and people get hurt and killed and it ' s never nice; but it happens . And hopefully soldiers try to be as careful as they can; but sometimes women and kids and old people and animals get hurt and killed by accident . It ' s sad but it happens . And then I explained that some of our best family friends are Jewish and/or Israelis; and I asked if he knew that (no; he didn ' t); and then I said that I didn ' t think that our friends were bad people at all (he agreed); and so I didn ' t think it was fa . . . . .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#give a source query and find the most similar in the relevant questions\n",
    "source_sentence = new_queries[3]\n",
    "sim_map = match_sentences.sentence_matching_word2vec(word2vecmodel, source_sentence, rel_answers)\n",
    "match_sentences.print_sim_sentences(sim_map, source_sentence, rel_answers)\n",
    "\n",
    "\n",
    "#train on relevant answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
